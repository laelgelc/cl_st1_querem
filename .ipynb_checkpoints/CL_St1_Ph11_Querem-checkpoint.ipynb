{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://laelgelcpublic.s3.sa-east-1.amazonaws.com/lael_50_years_narrow_white.png.no_years.400px_96dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": [
    "# Corpus Linguistics - Study 1 - Phase 1_1 - Quérem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efff8d8b-6456-4379-974e-d85ffe03bc6e",
   "metadata": {},
   "source": [
    "This solution responds to the requirement of adding the part-of-speech (POS) tag as a suffix to the lemmas determined by TreeTagger.\n",
    "\n",
    "It takes the file `tweets/tagged.txt` as input, performs the appropriate string transformations and returns `tweets/tagged2.txt` as output. Therefore, the solution should be executed after the execution of `treetagging.sh` is completed.\n",
    "\n",
    "Before moving on to running `tokenstypes.sh`, `tweets/tagged2.txt` should replace `tweets/tagged.txt` as shown below:\n",
    "\n",
    "```\n",
    "(my_env) eyamrog@Rog-ASUS:~/work/cl_st1_renata/tweets$ ll\n",
    "total 33172\n",
    "drwxr-xr-x 2 eyamrog eyamrog     4096 Sep 11 17:32 ./\n",
    "drwxr-xr-x 5 eyamrog eyamrog     4096 Sep 11 17:45 ../\n",
    "-rw-r--r-- 1 eyamrog eyamrog    89062 Sep 11 14:40 tagged.txt\n",
    "-rw-r--r-- 1 eyamrog eyamrog    99405 Sep 11 17:34 tagged2.txt\n",
    "-rw-r--r-- 1 eyamrog eyamrog 16842002 Sep 11 14:38 tweets.txt\n",
    "-rw-r--r-- 1 eyamrog eyamrog 16924433 Sep 11 14:20 tweets_ori.txt\n",
    "(my_env) eyamrog@Rog-ASUS:~/work/cl_st1_renata/tweets$ mv tagged.txt tagged_ori.txt\n",
    "(my_env) eyamrog@Rog-ASUS:~/work/cl_st1_renata/tweets$ mv tagged2.txt tagged.txt\n",
    "(my_env) eyamrog@Rog-ASUS:~/work/cl_st1_renata/tweets$ ll\n",
    "total 33172\n",
    "drwxr-xr-x 2 eyamrog eyamrog     4096 Sep 11 17:46 ./\n",
    "drwxr-xr-x 5 eyamrog eyamrog     4096 Sep 11 17:45 ../\n",
    "-rw-r--r-- 1 eyamrog eyamrog    99405 Sep 11 17:34 tagged.txt\n",
    "-rw-r--r-- 1 eyamrog eyamrog    89062 Sep 11 14:40 tagged_ori.txt\n",
    "-rw-r--r-- 1 eyamrog eyamrog 16842002 Sep 11 14:38 tweets.txt\n",
    "-rw-r--r-- 1 eyamrog eyamrog 16924433 Sep 11 14:20 tweets_ori.txt\n",
    "(my_env) eyamrog@Rog-ASUS:~/work/cl_st1_renata/tweets$ \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81a22bd-0059-4578-bfc6-29ecef3d2a6d",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80dde47b-60e9-4001-9587-cac5fac2cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b301ddf9-3758-42ba-9a6f-c1dd316ded08",
   "metadata": {},
   "source": [
    "## Importing `tweets/tagged.txt` into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9667e92f-5454-43fa-9d0c-2f5a77bf86c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets/tagged.txt', sep='|', names=['text_id', 'conversation', 'date', 'user', 'content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27649345-825e-4012-82e6-6f845de163ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>conversation</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t000000</td>\n",
       "      <td>v:287765295</td>\n",
       "      <td>d:2018-03-28</td>\n",
       "      <td>u:pelegrini65</td>\n",
       "      <td>c:Após\\tADP\\tapós~caluniar\\tVERB.Inf\\tcaluniar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t000001</td>\n",
       "      <td>v:16794066</td>\n",
       "      <td>d:2018-03-30</td>\n",
       "      <td>u:BlogdoNoblat</td>\n",
       "      <td>c:Bolsonaro\\tPROPN.Masc.Sing\\tbolsonaro~deve\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t000002</td>\n",
       "      <td>v:955901617148235776</td>\n",
       "      <td>d:2018-03-30</td>\n",
       "      <td>u:MariaOl25529153</td>\n",
       "      <td>c:@FlavioBolsonaro\\tVERB.Fin.Sing\\ttwitterhand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t000003</td>\n",
       "      <td>v:44449830</td>\n",
       "      <td>d:2018-03-28</td>\n",
       "      <td>u:lucianagenro</td>\n",
       "      <td>c:A\\tDET.Fem.Sing\\to~esquerda\\tNOUN.Fem.Sing\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t000004</td>\n",
       "      <td>v:912132396</td>\n",
       "      <td>d:2018-03-30</td>\n",
       "      <td>u:rocoguima</td>\n",
       "      <td>c:RT\\tPROPN.Masc.Sing\\trt~@AurystellaS\\tVERB.F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20596</th>\n",
       "      <td>t020596</td>\n",
       "      <td>v:1547227306913153026</td>\n",
       "      <td>d:2023-04-29</td>\n",
       "      <td>u:LuccaSo44679209</td>\n",
       "      <td>c:RT\\tNOUN.Masc.Sing\\trt~@LuccaSo44679209\\tNUM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20597</th>\n",
       "      <td>t020597</td>\n",
       "      <td>v:1547227306913153026</td>\n",
       "      <td>d:2023-04-29</td>\n",
       "      <td>u:LuccaSo44679209</td>\n",
       "      <td>c:@CiresCanisio\\tVERB.Fin.Sing\\ttwitterhandle~...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20598</th>\n",
       "      <td>t020598</td>\n",
       "      <td>v:1554492869825683457</td>\n",
       "      <td>d:2023-04-29</td>\n",
       "      <td>u:Andre19lll</td>\n",
       "      <td>c:@eunaovoupararde\\tVERB.Fin.Sing\\ttwitterhand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20599</th>\n",
       "      <td>t020599</td>\n",
       "      <td>v:1585200142440882179</td>\n",
       "      <td>d:2023-04-29</td>\n",
       "      <td>u:priscila19865</td>\n",
       "      <td>c:@ValS265451870\\tPROPN.Masc.Sing\\ttwitterhand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20600</th>\n",
       "      <td>t020600</td>\n",
       "      <td>v:1236078194878541824</td>\n",
       "      <td>d:2023-04-29</td>\n",
       "      <td>u:JDB33858086</td>\n",
       "      <td>c:@Joovito81551003\\tNUM\\ttwitterhandle~@odilab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20601 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       text_id           conversation          date               user  \\\n",
       "0      t000000            v:287765295  d:2018-03-28      u:pelegrini65   \n",
       "1      t000001             v:16794066  d:2018-03-30     u:BlogdoNoblat   \n",
       "2      t000002   v:955901617148235776  d:2018-03-30  u:MariaOl25529153   \n",
       "3      t000003             v:44449830  d:2018-03-28     u:lucianagenro   \n",
       "4      t000004            v:912132396  d:2018-03-30        u:rocoguima   \n",
       "...        ...                    ...           ...                ...   \n",
       "20596  t020596  v:1547227306913153026  d:2023-04-29  u:LuccaSo44679209   \n",
       "20597  t020597  v:1547227306913153026  d:2023-04-29  u:LuccaSo44679209   \n",
       "20598  t020598  v:1554492869825683457  d:2023-04-29       u:Andre19lll   \n",
       "20599  t020599  v:1585200142440882179  d:2023-04-29    u:priscila19865   \n",
       "20600  t020600  v:1236078194878541824  d:2023-04-29      u:JDB33858086   \n",
       "\n",
       "                                                 content  \n",
       "0      c:Após\\tADP\\tapós~caluniar\\tVERB.Inf\\tcaluniar...  \n",
       "1      c:Bolsonaro\\tPROPN.Masc.Sing\\tbolsonaro~deve\\t...  \n",
       "2      c:@FlavioBolsonaro\\tVERB.Fin.Sing\\ttwitterhand...  \n",
       "3      c:A\\tDET.Fem.Sing\\to~esquerda\\tNOUN.Fem.Sing\\t...  \n",
       "4      c:RT\\tPROPN.Masc.Sing\\trt~@AurystellaS\\tVERB.F...  \n",
       "...                                                  ...  \n",
       "20596  c:RT\\tNOUN.Masc.Sing\\trt~@LuccaSo44679209\\tNUM...  \n",
       "20597  c:@CiresCanisio\\tVERB.Fin.Sing\\ttwitterhandle~...  \n",
       "20598  c:@eunaovoupararde\\tVERB.Fin.Sing\\ttwitterhand...  \n",
       "20599  c:@ValS265451870\\tPROPN.Masc.Sing\\ttwitterhand...  \n",
       "20600  c:@Joovito81551003\\tNUM\\ttwitterhandle~@odilab...  \n",
       "\n",
       "[20601 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e582fe15-3b12-4966-9036-86460e0df513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_id         object\n",
       "conversation    object\n",
       "date            object\n",
       "user            object\n",
       "content         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0d2cf7-8d76-40cc-a0fd-48859305cf1d",
   "metadata": {},
   "source": [
    "### Inspecting a few texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0197402-1e98-4f53-979d-e28fe0e5d1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:Bolsonaro\\tPROPN.Masc.Sing\\tbolsonaro~deve\\tAUX.Fin.Sing\\tdever~saber\\tVERB.Inf\\tsaber~o\\tPRON.Masc.Sing\\to~que\\tPRON.Rel.Masc.Sing\\tque~está\\tAUX.Fin.Sing\\testar~fazendo\\tVERB.Ger\\tfazer~.\\tPUNCT.Sent\\t.~Porque\\tADV\\tporque~pela\\tADP_DET.Fem.Sing\\tpor_o~primeira\\tADJ.Fem.Sing\\tprimeiro~vez\\tNOUN.Fem.Sing\\tvez~,\\tPUNCT.Comma\\t,~o\\tDET.Masc.Sing\\to~eleitorado\\tNOUN.Masc.Sing\\teleitorado~feminino\\tADJ.Masc.Sing\\tfeminino~será\\tAUX.Fin.Sing\\tser~maior\\tADJ.Fem.Sing\\tgrande~nas\\tADP_DET.Fem.Plur\\tem_o~eleições\\tNOUN.Fem.Plur\\teleição~.\\tPUNCT.Sent\\t.~E\\tCCONJ\\te~ele\\tPRON.Masc.Sing\\tele~,\\tPUNCT.Comma\\t,~no\\tADP_DET.Masc.Sing\\tem_o~entanto\\tNOUN.Masc.Sing\\tentanto~,\\tPUNCT.Comma\\t,~só\\tADV\\tsó~fala\\tVERB.Fin.Sing\\tfalar~para\\tADP\\tpara~os\\tDET.Masc.Plur\\to~homens\\tNOUN.Masc.Plur\\thomem~e\\tCCONJ\\te~só\\tADV\\tsó~aparece\\tVERB.Fin.Sing\\taparecer~cercado\\tVERB.Part.Masc.Sing\\tcercar~de\\tADP\\tde~homens\\tNOUN.Masc.Plur\\thomem~,\\tPUNCT.Comma\\t,~parte\\tNOUN.Fem.Sing\\tparte~deles\\tADP_PRON.Masc.Plur\\tde_eles~armada\\tNOUN.Fem.Sing\\tarmada~.\\tPUNCT.Sent\\t.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1, 'content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ab9e3e-5789-4850-94c5-325b95fa9ec1",
   "metadata": {},
   "source": [
    "## Appending a `~` character at the end of each string of the column `content`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add4a4c6-5607-4c1e-9365-895b7b313652",
   "metadata": {},
   "source": [
    "The character `~` is required to allow for the detection of the string patterns to transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee9aac52-1c2a-4877-ac95-01491132d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending '~' to the end of each string in the 'content' column\n",
    "df['content'] = df['content'] + '~'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd906c1c-9345-4dfc-8370-ff37ac8bfe8a",
   "metadata": {},
   "source": [
    "### Inspecting a few texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88873a09-d242-478f-bd74-7e8818e26b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:Bolsonaro\\tPROPN.Masc.Sing\\tbolsonaro~deve\\tAUX.Fin.Sing\\tdever~saber\\tVERB.Inf\\tsaber~o\\tPRON.Masc.Sing\\to~que\\tPRON.Rel.Masc.Sing\\tque~está\\tAUX.Fin.Sing\\testar~fazendo\\tVERB.Ger\\tfazer~.\\tPUNCT.Sent\\t.~Porque\\tADV\\tporque~pela\\tADP_DET.Fem.Sing\\tpor_o~primeira\\tADJ.Fem.Sing\\tprimeiro~vez\\tNOUN.Fem.Sing\\tvez~,\\tPUNCT.Comma\\t,~o\\tDET.Masc.Sing\\to~eleitorado\\tNOUN.Masc.Sing\\teleitorado~feminino\\tADJ.Masc.Sing\\tfeminino~será\\tAUX.Fin.Sing\\tser~maior\\tADJ.Fem.Sing\\tgrande~nas\\tADP_DET.Fem.Plur\\tem_o~eleições\\tNOUN.Fem.Plur\\teleição~.\\tPUNCT.Sent\\t.~E\\tCCONJ\\te~ele\\tPRON.Masc.Sing\\tele~,\\tPUNCT.Comma\\t,~no\\tADP_DET.Masc.Sing\\tem_o~entanto\\tNOUN.Masc.Sing\\tentanto~,\\tPUNCT.Comma\\t,~só\\tADV\\tsó~fala\\tVERB.Fin.Sing\\tfalar~para\\tADP\\tpara~os\\tDET.Masc.Plur\\to~homens\\tNOUN.Masc.Plur\\thomem~e\\tCCONJ\\te~só\\tADV\\tsó~aparece\\tVERB.Fin.Sing\\taparecer~cercado\\tVERB.Part.Masc.Sing\\tcercar~de\\tADP\\tde~homens\\tNOUN.Masc.Plur\\thomem~,\\tPUNCT.Comma\\t,~parte\\tNOUN.Fem.Sing\\tparte~deles\\tADP_PRON.Masc.Plur\\tde_eles~armada\\tNOUN.Fem.Sing\\tarmada~.\\tPUNCT.Sent\\t.~'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1, 'content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f972af-e54d-405e-9b7c-b775990ff721",
   "metadata": {},
   "source": [
    "## Defining a function to transform the tagged strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15e46688-88b9-49bb-8ad5-3a165dadfb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_tagged_string(tagged_string):\n",
    "    # Ensure the input is a string\n",
    "    tagged_string = str(tagged_string)\n",
    "    # Function to transform each substring\n",
    "    def transform_substring(match):\n",
    "        parts = match.group(1).split('\\t')\n",
    "        if parts[0] in ['HASHTAG', 'EMOJI']:\n",
    "            substring = f'{parts[0]}\\t{parts[1]}~'\n",
    "        else:\n",
    "            tag = parts[0].replace('.', '_') # Replacing any occurrence of '.' by '_' to ensure compliance with the next stage of processing\n",
    "            substring = f'{parts[0]}\\t{parts[1]}_{tag}~'\n",
    "        return substring\n",
    "    \n",
    "    # Regular expression to match each substring delimited by '~'\n",
    "    #pattern = r'(\\w+\\t\\w+)~'\n",
    "    pattern = r'([a-zA-Z0-9_.]+\\t\\w+)~'\n",
    "    \n",
    "    # Apply the transformation\n",
    "    transformed_string = re.sub(pattern, lambda match: transform_substring(match), tagged_string)\n",
    "    \n",
    "    return transformed_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442936de-1113-4e6a-9b54-260a89457af7",
   "metadata": {},
   "source": [
    "## Transforming the tagged strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "547b6739-f07e-4b18-87dc-d8a1ddb0b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the tagged strings\n",
    "df['content'] = df['content'].apply(transform_tagged_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8546c1c8-0dd9-4d1c-a3b9-b73e9b9a463f",
   "metadata": {},
   "source": [
    "### Inspecting a few texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83358d63-1a81-4a04-a921-f39c0f56e8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:@FlavioBolsonaro\\tVERB.Fin.Sing\\ttwitterhandle_VERB_Fin_Sing~Mais\\tADV\\tmais_ADV~um\\tDET.Masc.Sing\\tum_DET_Masc_Sing~Romário\\tPROPN.Masc.Sing\\tromário_PROPN_Masc_Sing~na\\tADP_DET.Fem.Sing\\tem_o_ADP_DET_Fem_Sing~política\\tNOUN.Fem.Sing\\tpolítica_NOUN_Fem_Sing~,\\tPUNCT.Comma\\t,~que\\tSCONJ\\tque_SCONJ~Deus\\tPROPN.Masc.Sing\\tdeus_PROPN_Masc_Sing~ajude\\tVERB.Fin.Sing\\tajudar_VERB_Fin_Sing~os\\tDET.Masc.Plur\\to_DET_Masc_Plur~bolsonaro\\tNOUN.Masc.Sing\\tbolsonaro_NOUN_Masc_Sing~e\\tCCONJ\\te_CCONJ~não\\tADV\\tnão_ADV~deixem\\tVERB.Fin.Plur\\tdeixar_VERB_Fin_Plur~subir\\tVERB.Inf\\tsubir_VERB_Inf~para\\tADP\\tpara_ADP~cabeça\\tNOUN.Fem.Sing\\tcabeça_NOUN_Fem_Sing~,\\tPUNCT.Comma\\t,~só\\tADV\\tsó_ADV~falta\\tVERB.Fin.Sing\\tfaltar_VERB_Fin_Sing~agora\\tADV\\tagora_ADV~apoiar\\tVERB.Inf\\tapoiar_VERB_Inf~bbb\\tNOUN.Fem.Plur\\tbbb_NOUN_Fem_Plur~.\\tPUNCT.Sent\\t.~Nao\\tPROPN.Masc.Sing\\tnao_PROPN_Masc_Sing~caiam\\tVERB.Fin.Plur\\tcair_VERB_Fin_Plur~nessa\\tADP_DET.Fem.Sing\\tem_esse_ADP_DET_Fem_Sing~,\\tPUNCT.Comma\\t,~nos\\tPRON.Masc.Plur\\tnós_PRON_Masc_Plur~indiquem\\tVERB.Fin.Plur\\tindicar_VERB_Fin_Plur~alguém\\tPRON.Masc.Sing\\talguém_PRON_Masc_Sing~com\\tADP\\tcom_ADP~cérebro\\tNOUN.Masc.Sing\\tcérebro_NOUN_Masc_Sing~.\\tPUNCT.Sent\\t.~(\\tPUNCT.Par.Left\\t(~jogador\\tNOUN.Masc.Sing\\tjogador_NOUN_Masc_Sing~,\\tPUNCT.Comma\\t,~cantor\\tNOUN.Masc.Sing\\tcantor_NOUN_Masc_Sing~,\\tPUNCT.Comma\\t,~palhaço\\tNOUN.Masc.Sing\\tpalhaço_NOUN_Masc_Sing~,\\tPUNCT.Comma\\t,~ator\\tNOUN.Masc.Sing\\tator_NOUN_Masc_Sing~,\\tPUNCT.Comma\\t,~bbb\\tPROPN.Masc.Sing\\tbbb_PROPN_Masc_Sing~)\\tPUNCT.Par.Right\\t)~não\\tADV\\tnão_ADV~se\\tPRON\\tse_PRON~enquadra\\tVERB.Fin.Sing\\tenquadrar_VERB_Fin_Sing~.\\tPUNCT.Sent\\t.~FICA\\tVERB.Fin.Sing\\tficar_VERB_Fin_Sing~A\\tDET.Fem.Sing\\to_DET_Fem_Sing~DICA\\tNOUN.Fem.Sing\\tdica_NOUN_Fem_Sing~'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[2, 'content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9c0075-1231-4e5a-bf30-ca5bdfa7322f",
   "metadata": {},
   "source": [
    "## Exporting the DataFrame into `tweets/tagged2.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4d59f0b-22cf-4f33-b64b-f27f50ac9f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tweets/tagged2.txt', sep='|', index=False, header=False, encoding='utf-8', lineterminator='\\n', doublequote=False, escapechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ca4f59-aafb-4b18-afc1-6d53f78fa684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
